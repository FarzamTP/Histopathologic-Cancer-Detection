{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import layers\n",
    "import pandas\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"./dataset/train/\"\n",
    "TEST_PATH = \"./dataset/test/\"\n",
    "IMG_WIDTH, IMG_HEIGHT = 32, 32\n",
    "# Between 1 and 220025\n",
    "NUMBER_OF_SAMPLES = 200000\n",
    "LOAD_MATRICES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"./dataset/train_labels.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if null\n",
    "We should make sure that there are no `null` fields in the dataset.\n",
    "If there were any:\n",
    "* Remove data row\n",
    "* Fill according to other data (Which can not be done here, as the data are images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_empty_id_rows = len(df[df.id.isnull()])\n",
    "number_of_empty_label_rows = len(df[df.label.isnull()])\n",
    "\n",
    "if number_of_empty_id_rows == 0:\n",
    "    print(\"[NOTE]: Dataset 'id' column has no 'Null' values. No need to fill/remove rows.\")\n",
    "if number_of_empty_label_rows == 0:\n",
    "    print(\"[NOTE]: Dataset 'label' column has no 'Null' values. No need to fill/remove rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding dataset\n",
    "\n",
    "* Sampling positive and negative samples will help us understand the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tumor_samples = df[df.label == 1]\n",
    "number_of_posive_tumor_samples = len(positive_tumor_samples)\n",
    "number_of_posive_tumor_samples\n",
    "print(f\"Number of positive tumor samples: {number_of_posive_tumor_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tumor_samples = df[df.label == 0]\n",
    "number_of_negative_tumor_samples = len(negative_tumor_samples)\n",
    "number_of_negative_tumor_samples\n",
    "print(f\"Number of negative tumor samples: {number_of_negative_tumor_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Information provided by [Kaggle](https://www.kaggle.com/c/histopathologic-cancer-detection/data)\n",
    "\n",
    "In this dataset, you are provided with a large number of small pathology images to classify. Files are named with an image id. The `train_labels.csv` file provides the ground truth for the images in the train folder. You are predicting the labels for the images in the test folder. ***A positive label indicates that the center `32x32px` region of a patch contains at least one pixel of tumor tissue.*** Tumor tissue in the outer region of the patch ***does not*** influence the label. This outer region is provided to enable fully-convolutional models that do not use zero-padding, to ensure consistent behavior when applied to a whole-slide image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "fig.suptitle('Histopathologic scans of lymph node sections',fontsize=20)\n",
    "\n",
    "ax[0, 0].set_ylabel(\"Normal Tissue Samples\", size='large')\n",
    "ax[1, 0].set_ylabel(\"Positive Tumor Samples\", size='large')\n",
    "\n",
    "for i in range(5):\n",
    "    # Negative Tumor Tissue Sample\n",
    "    random_negative_sample = negative_tumor_samples.iloc[random.randint(0, number_of_negative_tumor_samples)]\n",
    "    random_negative_sample_id = random_negative_sample.id\n",
    "    random_negative_sample_label = random_negative_sample.label\n",
    "    random_negative_sample_path = os.path.join(TRAIN_PATH, random_negative_sample_id) + '.tif'\n",
    "    random_negative_img = cv2.imread(random_negative_sample_path)\n",
    "    random_negative_img = cv2.cvtColor(random_negative_img, cv2.COLOR_BGR2RGB)\n",
    "    rect = patches.Rectangle((32, 32), 32, 32, linewidth=3, edgecolor='b', facecolor='none')\n",
    "    ax[0, i].add_patch(rect)\n",
    "    ax[0, i].imshow(random_negative_img)\n",
    "    \n",
    "    # Positive Tumor Tissue Samples\n",
    "    random_positive_sample = positive_tumor_samples.iloc[random.randint(0, number_of_posive_tumor_samples)]\n",
    "    random_positive_sample_id = random_positive_sample.id\n",
    "    random_positive_sample_label = random_positive_sample.label\n",
    "    random_positive_sample_path = os.path.join(TRAIN_PATH, random_positive_sample_id) + '.tif'\n",
    "    random_positive_img = cv2.imread(random_positive_sample_path)\n",
    "    random_positive_img = cv2.cvtColor(random_positive_img, cv2.COLOR_BGR2RGB)\n",
    "    rect = patches.Rectangle((32, 32), 32, 32, linewidth=3, edgecolor='r', facecolor='none')\n",
    "    ax[1, i].imshow(random_positive_img)\n",
    "    ax[1, i].add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_convert_images_from_df(dataframe, base_dir):\n",
    "    img_list = []\n",
    "    img_label_list = []\n",
    "    total_number_of_data = len(dataframe)\n",
    "    for index, img_datum in dataframe.iterrows():\n",
    "        if index < NUMBER_OF_SAMPLES:\n",
    "            print(f\"{index + 1} out of {total_number_of_data}\")\n",
    "            print(f\"Image ID: {img_datum.id}, Label: {img_datum.label}\")\n",
    "            img_id = img_datum.id\n",
    "            img_label = df[df.id == img_id].iloc[0].label\n",
    "            img_path = os.path.join(base_dir, img_id) + '.tif'\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            img = np.asarray(img, dtype=float)\n",
    "            img /= 255.0\n",
    "            img_list.append(img)\n",
    "            img_label_list.append(img_label)\n",
    "    return img_list, img_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_convert_images_from_path(path):\n",
    "    img_list = []\n",
    "    img_id_list = []\n",
    "    for idx, img_name in enumerate(os.listdir(path)):\n",
    "        print(f\"{idx + 1} out of {len(os.listdir(path))}\")\n",
    "        img_id = img_name.split(\".tif\")[0]\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        img = np.asarray(img, dtype=float)\n",
    "        img /= 255.0\n",
    "        img_list.append(img)\n",
    "        img_id_list.append(img_id)\n",
    "    img_list = np.asarray(img_list, dtype='float')\n",
    "    img_id_list = np.asarray(img_id_list)\n",
    "    return img_list, img_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matrices():\n",
    "    X = np.load('./matrices/X_100k.npy')\n",
    "    y = np.load('./matrices/y_100k.npy')\n",
    "    \n",
    "    X_eval = np.load('./matrices/X_EVAL.npy')\n",
    "    ID_eval = np.load('./matrices/ID_EVAL.npy')\n",
    "    \n",
    "    return X, y, X_eval, ID_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MATRICES:\n",
    "    X, y, X_eval, ID_eval = load_matrices()\n",
    "    print(f\"X Shape: {X.shape}\")\n",
    "    print(f\"y Shape: {y.shape}\")\n",
    "    print(f\"X eval Shape: {X_eval.shape}\")\n",
    "    print(f\"ID eval Shape: {ID_eval.shape}\")\n",
    "else:\n",
    "    X, y = read_convert_images_from_df(df, TRAIN_PATH)\n",
    "    \n",
    "    X_eval, ID_eval = read_convert_images_from_path(TEST_PATH)\n",
    "    \n",
    "    X = np.asarray(X, dtype=float)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    np.save('./matrices/X_100k.npy', X)\n",
    "    np.save('./matrices/y_100k.npy', y)\n",
    "    \n",
    "    np.save('./matrices/X_EVAL.npy', X_eval)\n",
    "    np.save('./matrices/ID_EVAL.npy', id_list)\n",
    "    \n",
    "    print(\"X saved!\")\n",
    "    print(\"y saved!\")\n",
    "    \n",
    "    print(\"X eval saved!\")\n",
    "    print(\"ID eval saved!\")\n",
    "    \n",
    "    print(f\"X Shape: {X.shape}\")\n",
    "    print(f\"y Shape: {y.shape}\")\n",
    "    \n",
    "    print(f\"X eval Shape: {X_evall.shape}\")\n",
    "    print(f\"ID eval Shape: {ID_eval.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X Train shape: {x_train.shape}\\ny train Shape: {x_train.shape}\\nX Test shape: {x_test.shape}\\ny test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(32, 32, 3),\n",
    "    pooling=None,\n",
    "    classes=2,\n",
    "    classifier_activation=\"sigmoid\",\n",
    ")\n",
    "model = tf.keras.models.Sequential(vgg19.layers[:10])\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), batch_size=64, epochs=50, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test):\n",
    "    y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eval = predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./submission.csv'):\n",
    "    !rm submission.csv\n",
    "    print(\"Removed old version.\")\n",
    "\n",
    "with open('./submission.csv', 'w+') as f:\n",
    "    f.write(\"id,label\\n\")\n",
    "    for idx, y in enumerate(y_pred_eval):\n",
    "        f.write(f'{id_list[idx]},{y[0]}\\n')\n",
    "    print(\"Submission.csv file created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./submit_csv.sh 100k-training-sample-10layerVGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
